{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "df9c307d-9ad7-43a3-a4a8-ff7e224bb575"
   },
   "source": [
    "# Reduce overfitting\n",
    "* More data\n",
    "* 限制模型的复杂性（更浅层的网络或者正则化）\n",
    "* dropout\n",
    "* 数据增强\n",
    "* early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "d79fa5b6-5600-488f-9889-98702670280c"
   },
   "source": [
    "# 1.训练集&验证集&测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "d9487ab1-4727-43d4-a055-a90e70873d21"
   },
   "outputs": [],
   "source": [
    "train_db ,val_db = torch.utils.data.random_split(train_db,[50000,10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "3d2bba84-6c88-4098-98c1-4c25a211f548"
   },
   "source": [
    "# 2.正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "c4a89691-a1d1-4fdd-8fd7-2ecfb946e29d"
   },
   "source": [
    "* 在定义优化器的时候设定weigth_decay，即L2范数前面的参数<br/>\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = learning_rate,weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "32de2f35-e634-43ee-95f9-97828edc798f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f9f66f9250e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# L1-regualarization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mregularization_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mregularization_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassify_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# L1-regualarization\n",
    "regularization_loss = 0\n",
    "for param in model.parameters():\n",
    "    regularization_loss+=torch.sum(torch.abs(param))\n",
    "classify_loss = criteon(logits,target)\n",
    "loss=classify_loss+0.01*regularization_loss\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "70957495-c32f-4fbc-94a2-f9f42ce53f77"
   },
   "source": [
    "# 3.动量（惯性的意思）\n",
    "args.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "3f203dd1-947b-4a13-a455-fa476f5eda0a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5e575e9badc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdoel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(mdoel.parameters(),args.lr,momentum = args.momentum,weight_decay = args.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "a0cd3352-9fee-4165-9ba1-1c1f42fd3e17"
   },
   "source": [
    "# 4.学习率衰减\n",
    "* torch.optim.lr_scheduler中提供了基于多种epoch数目，调整学习率的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "6fb8c0e7-7ae5-4a2c-adc5-f95dc2c27158"
   },
   "source": [
    "## 4.1ReduceLROnPlateau\n",
    "* torch.optim.lr_scheduler.ReduceLROnPlateau：基于测量指标对学习率进行动态的下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "09e10144-d147-476e-9191-8dbaaefc95b0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4bc672bc78c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcooldown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode = 'min',factor = 0.1,patience = 10,verbose = False,threshold = 0.0001,threshold_model = 'rel',cooldown = 0,min_lr = 0,eps = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "9c39c07b-15d3-4594-83d1-7250da80f7a7"
   },
   "source": [
    "## 训练过程中，optimizer会把learning_rate交给scheduler管理\n",
    "* 当指标（比如loss）连续patience次还没有改进的时候，需要降低学习率，factor为每次下降的比例。\n",
    "* scheduler.step(loss_val)每调用一次就会监听一次loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b7f12573-1102-45ea-b459-00a8727f2309"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),args.lr,momentum = args.momentum,weight_decay = args.weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer,mode='min',factor = 0.1)\n",
    "\n",
    "\n",
    "for epoch in xrange(args.start_epoch,args.epochs):\n",
    "    train(train_loader,model,criterion,optimizer,epoch)\n",
    "    result_avg,loss_val = validate(val_loader,model,criterion,epoch)\n",
    "    scheduler.step(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "bdd15c36-acb8-415f-9056-4593c454a302"
   },
   "source": [
    "## 4.2StepLR\n",
    "* torch.optim.lr_scheduler.StepLR:基于epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "c45aa092-2c4f-49fb-87ea-fee2e441d30e"
   },
   "source": [
    "* torch.optim.lr_scheduler.StepLR(optimizer,step_size,gamma = 0.1,last_epoch = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "012791bc-3941-49fe-a874-9dab7e177073"
   },
   "outputs": [],
   "source": [
    "# 当epoch每经过step_size后，学习率都变为初始学习率的gamma倍\n",
    "# lr = 0.05  if epoch <30\n",
    "# lr = 0.005 if 30<=epoch <=60\n",
    "# lf = 0.005 if 60<=epoch <=90\n",
    "scheduler = StepLR(optimizer,step_size = 30,gamma = 0.1)\n",
    "for epoch in range(1000):\n",
    "    scheduler.step()\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "ca5fb285-0fcf-4a2b-b66c-ce9b0dc2061f"
   },
   "source": [
    "# 5.EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "ebd9f771-6100-46b8-987a-0a2b131740dd"
   },
   "source": [
    "# 6.Dropout随机失活\n",
    "* 遍历每一层，设置消除神经网络中的节点概率，得到精简后的一个样本\n",
    "* torch.nn.Dropout(p = dropout_prob)\n",
    "* p表示的是删除节点的比例（tip:tensorflow中keep_prob表示保留节点数的比例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "13c89a9d-3cb3-4f4c-904f-b606fd31c229"
   },
   "outputs": [],
   "source": [
    "net_dropped = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,200),\n",
    "    torch.nn.Dropout(0.8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(200,200),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(200,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "161cfbfd-0d45-4da7-9fe7-9e8904db408c"
   },
   "source": [
    "# 测试阶段无需使用dropOut\n",
    "* 在train之前执行net_dropped.train()相当于启动dropout\n",
    "* 测试之前执行net_dropped.eval()相当于不启动dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ef72f536-0dc2-4ba3-a7db-d0ba9761b02f"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "#     train\n",
    "    net_dropped.train()\n",
    "    for batch_idx,(data,target) in enumerater(train_loader):\n",
    "        ...\n",
    "    net_dropped.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data,target in test_loader:\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
